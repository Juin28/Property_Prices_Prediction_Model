{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Prices Prediction Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  from google.colab import drive\n",
    "  drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd \"/content/drive/MyDrive/\"+ # ADD YOUR PATH HERE\n",
    "# %ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "As a partner of a property investment company, your objective is to make a profit from investing in and the eventual sale of invested properties. To do this, you need a solid property prediction model based on historical property transactions. To enable the prediction of future property prices from your prediction model compared against prevailing asking prices. So that the future sale of a property will bring in a nice profit.\n",
    "\n",
    "The Hong Kong Island areas of Central, Sheung Wan and Sai Wan private housing dataset is a Excel Comma Separated Value (CSV) text file, which include 29 features and 1139 observations. Each observation represents the sale of a home and each feature is an attribute describing the house or the circumstance of the sale. \n",
    "\n",
    "The features include string, boolean, categorical and numerical variables. These features are as follows:\n",
    "\n",
    "| Field Label | Field description | Data format | Remark |\n",
    "| --- | --- | --- | --- |\n",
    "| Reg_Date | Register date in Land Registry | DD/MM/YYYY |  |\n",
    "| Reg_Year | Register year | YYYY | Extract from Reg_Date field |\n",
    "| Prop_Name_ENG | Name of the property | String |  |\n",
    "| Address_ENG | Address of the property | String |  |\n",
    "| Prop_Type | Type of the property | Boolean (Single/ Estate) |  |\n",
    "| Tower | Tower number | String |  |\n",
    "| Floor | Floor of the property | Numeric |  |\n",
    "| Floor_(H/M/L) | Floor category (H/M/L) | Category (H/M/L) | Floor 0 to 15 => L, Floor 16 to 34 => M, Floor upper than 35 => H |\n",
    "| Flat | Flat of the property | String |  |\n",
    "| Bed_Room | No. of bed room of the property | Numeric |  |\n",
    "| Roof | Roof included? | Boolean (Y/N) |  |\n",
    "| Build_Ages | Building age at registration | String |  |\n",
    "| Rehab_Year | Year of building rehabilitation schemes | Numeric | [Website](https://www.ura.org.hk/en/project/rehabilitation/building-rehabilitation-schemes) |\n",
    "| Eff_Build_Age | Effective building age that consider the building rehabilitation schemes | String | If URA is 0, Eff_Age = Build_Ages. If URA is not 0, (Reg_Year)+{[Build_Age-(Reg_Year-URA)]*2/3} |\n",
    "| SalePrice_10k | Sale Price | Numeric |  |\n",
    "| SaleableArea | Saleable area of the property | Numeric |  |\n",
    "| Gross Area | Gross area of the property | Numeric |  |\n",
    "| SaleableAreaPrice | Price per saleable area | Numeric |  |\n",
    "| Gross Area_Price | Price per gross area | Numeric |  |\n",
    "| Kindergarten | No. of kindergarten near the property | Numeric |  |\n",
    "| Primary_Schools | No. of primary schools near the property | Numeric |  |\n",
    "| Secondary_Schools | No. of secondary schools near the property | Numeric |  |\n",
    "| Parks | No. of public parks near the property | Numeric |  |\n",
    "| Library | No. of library near the property | Numeric |  |\n",
    "| Bus_Route | No. of bus stations near the property | Numeric |  |\n",
    "| Mall | No. of shopping mall near the property | Numeric | Shun Tak Centre, Western Market, Infinitus Plaza |\n",
    "| Wet Market | No. of wet market near the property | Numeric |  |\n",
    "| Latitude | The latitude of the property | Numeric | [Website](http://www.mapdevelopers.com/batch_geocode_tool.php) |\n",
    "| Longitude | The longitude of the property | Numeric | [Website](http://www.mapdevelopers.com/batch_geocode_tool.php) |\n",
    "| Edu_Inst | The education institution near the property | Numeric | Sum of Kindergarten, Primary_Schools and Secondary_Schools |\n",
    "\n",
    "\n",
    "\n",
    "Relevant information on the datasets can be retrieved by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Hong Kong Properties dataset \n",
    "pd.set_option('display.max_columns', None)\n",
    "dataframe = pd.read_csv('HKProp_Dataset.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the shape of the dataframe we used in this lab. The correct shape should be `(1100, 28)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape for the dataframe\n",
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Sale Price distribution\n",
    "\n",
    "Before we start our research, we first have a visualization to better understand the distribution of our data. The target value for this analysis is the sale price, which is `'SalePrice_10k'` in the dataframe. We will use the sale price of different properties as the radius for the circle marker and visualize them in the map. We use different color to plot the sale price for `(0,600)`, `(600,1000]`, and `(1000,+âˆž)`\n",
    "\n",
    "You can explore the sale price directly on the map. By clicking the circle on the map, you can see the name, type, and floor of different properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sale price\n",
    "hongkong_map = folium.Map(location=[22.281442,114.152991],\n",
    "                        zoom_start=15,\n",
    "                   tiles=\"cartodbpositron\")\n",
    "\n",
    "for i in range(len(dataframe)):\n",
    "    lat = dataframe['Latitude'].iloc[i] \n",
    "    long = dataframe['Longitude'].iloc[i] \n",
    "    SalePrice_10k = dataframe['SalePrice_10k'].iloc[i]\n",
    "    radius = min(SalePrice_10k/100, 20)\n",
    "\n",
    "    if SalePrice_10k > 1000:\n",
    "        color = \"#008080\"  # blue high price\n",
    "    elif SalePrice_10k < 600:\n",
    "        color = \"#9BCD9B\"  # grey cheap price\n",
    "    else:\n",
    "        color = \"#9C9C9C\"  # green normal price\n",
    "    \n",
    "    popup_text = \"\"\"Name : {}<br>\n",
    "                Type : {}<br>\n",
    "                Floor : {}<br>\"\"\"\n",
    "    \n",
    "    popup_text = popup_text.format(\n",
    "        dataframe['Prop_Name_ENG'].iloc[i], \n",
    "        dataframe['Prop_Type'].iloc[i], \n",
    "        dataframe['Floor'].iloc[i]\n",
    "        )\n",
    "\n",
    "    folium.CircleMarker(location = [lat, long], popup= popup_text,radius = radius, color = color, fill = True).add_to(hongkong_map)\n",
    "\n",
    "hongkong_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another direct visualization tool to check the locations for the most sold properties is to use a heatmap. You can zoom in or zoom out to find the location distribution of these sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(dataframe)\n",
    "lat = np.array(dataframe[\"Latitude\"][0:num])                       \n",
    "lon = np.array(dataframe[\"Longitude\"][0:num])                        \n",
    "rent_room = np.array(dataframe[\"SalePrice_10k\"][0:num],dtype=float)    \n",
    "\n",
    "data1 = [[lat[i],lon[i],rent_room[i]] for i in range(num)]    \n",
    "\n",
    "hongkong_map = folium.Map(location=[22.285442,114.152991],\n",
    "                        zoom_start=16) \n",
    "HeatMap(data1).add_to(hongkong_map) \n",
    "folium.TileLayer('cartodbpositron').add_to(hongkong_map)\n",
    "\n",
    "hongkong_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having a glance at the dataset distribution, you may now have a brief understanding of how the sale prices are connected to the locations. Here we preprocess and combine the features in the datasheet to construct training and validation data `X_trainval, y_trainval`, and testing data `X_test, y_test` for training and evaluating our MLP model. **Please DO NOT modify the code**. The correct shape should be `(1000, 166) (100, 166) (1000,) (100,)` for `X_trainval, X_test, y_trainval, y_test`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes for generating input data and ground truth labels\n",
    "\n",
    "y = np.array(dataframe['SalePrice_10k'])\n",
    "\n",
    "# replace '--' with 0, replace $ with space.\n",
    "dataframe = dataframe.replace('--', '0').replace('$', '')  \n",
    "Reg_Date = pd.to_datetime(np.array(dataframe['Reg_Date']),infer_datetime_format=True)\n",
    "Days_to_reg_date = [int(t.days) for t in (Reg_Date - datetime.datetime.today())]\n",
    "Bedroom = dataframe['Bed_Room'].replace('Studio', '0').fillna(0)\n",
    "Is_studio = [1 if e == 0 else 0 for e in np.array(dataframe['Bed_Room'])] \n",
    "\n",
    "SaleableArea = [int(str(t).replace(',', '').replace('nan', '0')) for t in dataframe['SaleableArea']]\n",
    "SaleableAreaPrice = [int(str(t).replace(',', '').replace('$', '0').replace('nan', '0')) for t in dataframe['SaleableAreaPrice']]\n",
    "GrossArea = [int(str(t).replace(',', '').replace('nan', '0')) for t in dataframe['Gross Area']]\n",
    "GrossAreaPrice = [int(str(t).replace(',', '').replace('$', '0').replace('nan', '0')) for t in dataframe['Gross Area_Price']]\n",
    "\n",
    "X = np.concatenate([np.array(Days_to_reg_date).reshape(-1, 1), np.array(Bedroom).reshape(-1, 1),\n",
    "                        np.array(Is_studio).reshape(-1, 1), np.array(SaleableArea).reshape(-1, 1),\n",
    "                        np.array(GrossAreaPrice).reshape(-1, 1),\n",
    "                        np.array(GrossArea).reshape(-1, 1),\n",
    "                        np.array(SaleableAreaPrice).reshape(-1, 1),\n",
    "                        np.array(pd.get_dummies(dataframe[['Flat', 'Prop_Type', 'Tower', 'Roof']])),\n",
    "                       np.array(dataframe[['Floor', 'Build_Ages', 'Rehab_Year', 'Kindergarten', 'Primary_Schools', 'Secondary_Schools',\n",
    " 'Parks', 'Library', 'Bus_Route', 'Mall', 'Wet Market', 'Latitude', 'Longitude']].fillna(0))], axis=1)\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = X[:1000], X[1000:], y[:1000], y[1000:]\n",
    "print(X_trainval.shape, X_test.shape, y_trainval.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data_numpy(X, y, numpy_seed):\n",
    "    # fix the random seed\n",
    "    np.random.seed(numpy_seed)\n",
    "\n",
    "    num_sample = X.shape[0]\n",
    "\n",
    "    order = np.random.choice(num_sample, num_sample, replace = False)\n",
    "\n",
    "    X_shuffle = X[order]\n",
    "    y_shuffle = y[order]\n",
    "\n",
    "    return X_shuffle, y_shuffle\n",
    "\n",
    "def train_val_split(X_trainval, y_trainval, train_size, numpy_seed):\n",
    "    X_shuffle, y_shuffle = shuffle_data_numpy(X_trainval, y_trainval, numpy_seed)\n",
    "\n",
    "    X_train = X_shuffle[ : train_size, : ]\n",
    "    y_train = y_shuffle[ : train_size]\n",
    "\n",
    "    X_val = X_shuffle[train_size : , : ]\n",
    "    y_val = y_shuffle[train_size : ]\n",
    "\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_val_split(X_trainval, y_trainval, 700, 42)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No additional import allowed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def MyModel(num_dense_layer, dense_layer_unit, input_dim, dropout_ratio):\n",
    "    # Create a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    for i in range(num_dense_layer):\n",
    "      model.add(Dense(units = dense_layer_unit, activation = \"relu\", kernel_initializer=\"uniform\"))\n",
    "      model.add(Dropout(dropout_ratio))\n",
    "\n",
    "    model.add(Dense(units = 1, activation = \"linear\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.build(input_shape=(None, input_dim))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep them as the default setting for the model you submitted to ZINC!\n",
    "num_dense_layer = 2\n",
    "dense_layer_unit = 40\n",
    "input_dim = len(X_train[0])\n",
    "dropout_ratio = 0\n",
    "\n",
    "model = MyModel(num_dense_layer, dense_layer_unit, input_dim, dropout_ratio)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def MyModel_Training(model, X_train, y_train, X_val, y_val, batchsize, train_epoch):\n",
    "    adam_optimizer = Adam(learning_rate = 1e-3)\n",
    "    \n",
    "    model.compile( \n",
    "        optimizer = adam_optimizer,\n",
    "        loss = \"mean_squared_error\",\n",
    "        metrics = [\"mae\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs = train_epoch, validation_data = (X_val, y_val), batch_size = batchsize, validation_batch_size = batchsize)\n",
    "\n",
    "    return history, model\n",
    "\n",
    "model = MyModel(num_dense_layer, dense_layer_unit, input_dim, dropout_ratio)\n",
    "\n",
    "batchsize = 8\n",
    "train_epoch = 50\n",
    "\n",
    "history, model = MyModel_Training(model, X_train, y_train, X_val, y_val, batchsize, train_epoch)\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Mean Average Error (MAE): {test_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./mlp_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the model you just saved and check the mean average error again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "mlp_model = load_model(\"./mlp_model.keras\")\n",
    "test_loss, test_mae = mlp_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Mean Average Error (MAE): {test_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check of your MLP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['mae'], label='Training mae')\n",
    "plt.plot(history.history['val_mae'], label='Validation mae')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How accurate can your model predicted the sales price? Let's check!\n",
    "Here we plot the predicted sale price (y-axis) vs. ground truth sales price (x-axis). If you find most of the points distributed near the line `y=x`, your MLP model can help make a prediction for the house price!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test).flatten()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel('Ground True Values for Sale Price (10k HKD)')\n",
    "plt.ylabel('Predictions for Sale Price (10k HKD)')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 3000], [-100, 3000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
